{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "# your favorite machine learning tracking tool\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import scipy.io\n",
    "import skimage.io\n",
    "from skimage.color import gray2rgb\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset, Dataset\n",
    "\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "\n",
    "from torchvision import transforms\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarsDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mat_file, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        labels = scipy.io.loadmat(mat_file)\n",
    "        self.labels = labels['annotations'][0]\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.image_dir,\n",
    "                                self.labels[idx][5][0])\n",
    "        image = skimage.io.imread(img_name)\n",
    "        if len(image.shape) < 3:\n",
    "            image = gray2rgb(image)\n",
    "\n",
    "        label = self.labels[idx][4][0][0]\n",
    "        \n",
    "        sample = [image.copy(), label.copy()]\n",
    "\n",
    "        if self.transform:\n",
    "            sample[0] = self.transform(sample[0])\n",
    "            sample[1] = torch.tensor(sample[1])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, train_mat, test_mat, train_data_dir: str = './', test_data_dir: str = './'):\n",
    "        super().__init__()\n",
    "        self.train_mat = train_mat\n",
    "        self.test_mat = test_mat\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.test_data_dir = test_data_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.num_classes = 197\n",
    "\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=(-10, 10)),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            transforms.Resize((250,250)),\n",
    "            transforms.RandomCrop((224, 224))\n",
    "        ])\n",
    "        \n",
    "        self.transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            transforms.Resize((224,224))\n",
    "        ])\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.cars_train = CarsDataset(self.train_mat, self.train_data_dir, transform=self.transform_train)\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == 'test' or stage is None:\n",
    "            cars_full_test = CarsDataset(self.test_mat, self.test_data_dir, transform=self.transform_test)\n",
    "            self.cars_test, self.cars_val = random_split(cars_full_test, [7041, 1000])\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cars_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cars_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cars_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePredictionLogger(pl.callbacks.Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Bring the tensors to CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Get model prediction\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)\n",
    "        # Log the images as wandb Image\n",
    "        trainer.logger.experiment.log({\n",
    "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
    "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
    "                                                 preds[:self.num_samples], \n",
    "                                                 val_labels[:self.num_samples])]\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SEBlock\n",
    "2. DropSample\n",
    "3. BatchNorm\n",
    "4. Correct kernel sizes\n",
    "5. Resudual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnAct(nn.Module):\n",
    "    \"\"\"Layer grouping a convolution, batchnorm, and activation function\"\"\"\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, \n",
    "                 stride=1, padding=0, groups=1, bias=False,\n",
    "                 bn=True, act=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(n_in, n_out, kernel_size=kernel_size,\n",
    "                              stride=stride, padding=padding,\n",
    "                              groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(n_out) if bn else nn.Identity()\n",
    "        self.act = nn.SiLU() if act else nn.Identity()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-excitation block\"\"\"\n",
    "    def __init__(self, n_in, r=24):\n",
    "        super().__init__()\n",
    "\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(nn.Conv2d(n_in, n_in//r, kernel_size=1),\n",
    "                                        nn.SiLU(),\n",
    "                                        nn.Conv2d(n_in//r, n_in, kernel_size=1),\n",
    "                                        nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.squeeze(x)\n",
    "        y = self.excitation(y)\n",
    "        return x * y\n",
    "\n",
    "class DropSample(nn.Module):\n",
    "    \"\"\"Drops each sample in x with probability p during training\"\"\"\n",
    "    def __init__(self, p=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if (not self.p) or (not self.training):\n",
    "            return x\n",
    "\n",
    "        batch_size = len(x)\n",
    "        random_tensor = torch.FloatTensor(batch_size, 1, 1, 1).uniform_()\n",
    "        \n",
    "        if x.device.type == 'cuda':\n",
    "            random_tensor = random_tensor.cuda()\n",
    "        bit_mask = self.p<random_tensor\n",
    "\n",
    "        x = x.div(1-self.p)\n",
    "        x = x * bit_mask\n",
    "        return x\n",
    "\n",
    "class MBConvN(nn.Module):\n",
    "    \"\"\"MBConv with an expansion factor of N, plus squeeze-and-excitation\"\"\"\n",
    "    def __init__(self, n_in, n_out, expansion_factor,\n",
    "                kernel_size=3, stride=1, r=24, p=0):\n",
    "        super().__init__()\n",
    "\n",
    "        padding = (kernel_size-1)//2\n",
    "        expanded = expansion_factor*n_in\n",
    "        self.skip_connection = (n_in == n_out) and (stride == 1)\n",
    "\n",
    "        self.expand_pw = nn.Identity() if (expansion_factor == 1) else ConvBnAct(n_in, expanded, kernel_size=1)\n",
    "        self.depthwise = ConvBnAct(expanded, expanded, kernel_size=kernel_size, \n",
    "                                    stride=stride, padding=padding, groups=expanded)\n",
    "        self.se = SEBlock(expanded, r=r)\n",
    "        self.reduce_pw = ConvBnAct(expanded, n_out, kernel_size=1,\n",
    "                                    act=False)\n",
    "        self.dropsample = DropSample(p)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.expand_pw(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.se(x)\n",
    "        x = self.reduce_pw(x)\n",
    "\n",
    "        if self.skip_connection:\n",
    "            x = self.dropsample(x)\n",
    "            x = x + residual\n",
    "\n",
    "        return x\n",
    "\n",
    "class MBConv1(MBConvN):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3,\n",
    "                stride=1, r=24, p=0):\n",
    "        super().__init__(n_in, n_out, expansion_factor=1,\n",
    "                            kernel_size=kernel_size, stride=stride,\n",
    "                            r=r, p=p)\n",
    "    \n",
    " \n",
    "class MBConv6(MBConvN):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3,\n",
    "                stride=1, r=24, p=0):\n",
    "        super().__init__(n_in, n_out, expansion_factor=6,\n",
    "                            kernel_size=kernel_size, stride=stride,\n",
    "                            r=r, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(pl.LightningModule):\n",
    "    def __init__(self, w_factor=1, d_factor=1, num_classes=1000, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        base_widths = [(32, 16), (16, 24), (24, 40),\n",
    "                       (40, 80), (80, 112), (112, 192),\n",
    "                       (192, 320), (320, 1280)]\n",
    "        base_depths = [1, 2, 2, 3, 3, 4, 1]\n",
    "\n",
    "        scaled_widths = [(self.__scale_width(w[0], w_factor), self.__scale_width(w[1], w_factor)) \n",
    "                        for w in base_widths]\n",
    "        scaled_depths = [math.ceil(d_factor*d) for d in base_depths]\n",
    "        \n",
    "        kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n",
    "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
    "        ps = [0, 0.029, 0.057, 0.086, 0.114, 0.143, 0.171]\n",
    "\n",
    "        self.stem = ConvBnAct(3, scaled_widths[0][0], stride=2, padding=1)\n",
    "        \n",
    "        stages = []\n",
    "        for i in range(7):\n",
    "            layer_type = MBConv1 if (i == 0) else MBConv6\n",
    "            r = 4 if (i == 0) else 24\n",
    "            stage = self.__create_stage(*scaled_widths[i], scaled_depths[i],\n",
    "                                        layer_type, kernel_size=kernel_sizes[i], \n",
    "                                        stride=strides[i], r=r, p=ps[i])\n",
    "            stages.append(stage)\n",
    "        self.stages = nn.Sequential(*stages)\n",
    "\n",
    "        self.pre_head = ConvBnAct(*scaled_widths[-1], kernel_size=1)\n",
    "\n",
    "        self.head = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                                nn.Flatten(),\n",
    "                                nn.Linear(scaled_widths[-1][1], num_classes),\n",
    "                                nn.Sigmoid())\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.f1 = MulticlassF1Score(num_classes=num_classes)\n",
    "    \n",
    "    def __create_stage(self, n_in, n_out, num_layers, layer_type, \n",
    "                     kernel_size=3, stride=1, r=24, p=0):\n",
    "        \"\"\"Creates a Sequential consisting of [num_layers] layer_type\"\"\"\n",
    "        layers = [layer_type(n_in, n_out, kernel_size=kernel_size,\n",
    "                             stride=stride, r=r, p=p)]\n",
    "        layers += [layer_type(n_out, n_out, kernel_size=kernel_size,\n",
    "                              r=r, p=p) for _ in range(num_layers-1)]\n",
    "        layers = nn.Sequential(*layers)\n",
    "        return layers\n",
    "    \n",
    "    def __scale_width(self, w, w_factor):\n",
    "        \"\"\"Scales width given a scale factor\"\"\"\n",
    "        w *= w_factor\n",
    "        new_w = (int(w+4) // 8) * 8\n",
    "        new_w = max(8, new_w)\n",
    "        if new_w < 0.9*w:\n",
    "            new_w += 8\n",
    "        return int(new_w)\n",
    "    \n",
    "    def __feature_extractor(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stages(x)\n",
    "        x = self.pre_head(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.__feature_extractor(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        \n",
    "        # training metrics\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        f1_score = self.f1(preds, y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log('train_F1', f1_score, on_step=True, on_epoch=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "\n",
    "        # validation metrics\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        f1_score = self.f1(preds, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_F1', f1_score, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        \n",
    "        # validation metrics\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "        f1_score = self.f1(preds, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_F1', f1_score, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = CarsDataModule(train_mat='data/cars_train_annos.mat',\n",
    "                    test_mat='data/cars_test_annos.mat',\n",
    "                    train_data_dir='data/cars_train',\n",
    "                    test_data_dir='data/cars_test',\n",
    "                    batch_size=32)\n",
    "# To access the x_dataloader we need to call prepare_data and setup.\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "# Samples required by the custom ImagePredictionLogger callback to log image predictions.\n",
    "val_samples = next(iter(dm.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples[0], val_samples[1]\n",
    "val_imgs.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PnthrLeo\\.conda\\envs\\image-processing\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type              | Params\n",
      "-----------------------------------------------\n",
      "0 | stem     | ConvBnAct         | 928   \n",
      "1 | stages   | Sequential        | 3.6 M \n",
      "2 | pre_head | ConvBnAct         | 412 K \n",
      "3 | head     | Sequential        | 252 K \n",
      "4 | loss     | CrossEntropyLoss  | 0     \n",
      "5 | f1       | MulticlassF1Score | 0     \n",
      "-----------------------------------------------\n",
      "4.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 M     Total params\n",
      "17.040    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  32%|â–ˆâ–ˆâ–ˆâ–      | 92/287 [04:22<09:15,  2.85s/it, loss=4.98, v_num=guix, val_loss=5.000, val_F1=0.000171] "
     ]
    }
   ],
   "source": [
    "model = EfficientNet(num_classes=dm.num_classes)\n",
    "\n",
    "# Initialize wandb logger\n",
    "wandb_logger = WandbLogger(project='wandb-lightning', job_type='train')\n",
    "\n",
    "# Initialize Callbacks\n",
    "early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint()\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(max_epochs=40,\n",
    "                     accelerator='gpu',\n",
    "                     devices=1,\n",
    "                     logger=wandb_logger,\n",
    "                     callbacks=[ImagePredictionLogger(val_samples),\n",
    "                                checkpoint_callback],\n",
    "                     )\n",
    "\n",
    "# Train the model âš¡ðŸš…âš¡\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# Evaluate the model on the held-out test set âš¡âš¡\n",
    "trainer.test(dataloaders=dm.test_dataloader())\n",
    "\n",
    "# Close wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('image-processing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f2d1712ad61a1680ef1e32d8f888e03ab49bcfa8a6ea21125ccac88d7602bd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
